{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZHWe772ZD2r"
      },
      "source": [
        "## Your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOuyp6H5ZD2r"
      },
      "source": [
        "Now it's your turn! See if you can replicate the clustering pipeline above but with our corpus of NYT obituaries. I've started you out by reading in the files, as we did last class, but I've left most of the remaining work for you."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Import libraries"
      ],
      "metadata": {
        "id": "7EEJsg_mt4n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries for extracting filenames from filepaths\n",
        "import gdown\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from sklearn import feature_extraction"
      ],
      "metadata": {
        "id": "thLpE3S7vkp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg1OFLjCZD2r"
      },
      "source": [
        "### 1. Read in the files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First step, read in the files\n",
        "\n",
        "# Download the zip file\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1G0Aeg8dzZGPOCNFZ77U-s9CfEnR8efbB', quiet=False)"
      ],
      "metadata": {
        "id": "85im95bvj_S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip it\n",
        "!unzip NYT-Obituaries.zip"
      ],
      "metadata": {
        "id": "TXnZJAXTkCOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxg0VDz4ZD2r"
      },
      "outputs": [],
      "source": [
        "# Now, collect filepaths as files\n",
        "directory = \"NYT-Obituaries/\" # your path will be different!\n",
        "files = glob.glob(f\"{directory}/*.txt\")\n",
        "\n",
        "# and collect obit titles, which are also the final section of the filepaths\n",
        "obit_titles = [Path(file).stem for file in files]\n",
        "\n",
        "# print out the number of files to make sure it worked\n",
        "print(\"Number of files: \" + str(len(files)))\n",
        "\n",
        "# print out the title of the first obit to make sure that part worked\n",
        "print(\"Title of first file: \" + obit_titles[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBLo79weZD2r"
      },
      "source": [
        "### 2. Pre-process the files into a single list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1UvFiJ1ZD2r"
      },
      "outputs": [],
      "source": [
        "# As we know, the sk-learn tf-idf vectorizer creates its vectors from a list,\n",
        "# with each item in the list containing the text of a single document\n",
        "\n",
        "# Here, we need to get from our list of filenames -- called files -- created in the\n",
        "# list above, to another list, which we can call obits, which contains the text of\n",
        "# each file\n",
        "\n",
        "obits = []\n",
        "\n",
        "for file in files:\n",
        "    with open(file, encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "        obits.append(text)\n",
        "\n",
        "# see what one looks like\n",
        "print(obits[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6j-qSJGZD2r"
      },
      "source": [
        "### 3. Create the tf-idf vectors and the list of features\n",
        "\n",
        "**Your turn!**\n",
        "\n",
        "Note that you can modify this code from the tf-idf cell in the other notebook, but remember that we're using a new list call \"obits\" rather than the \"synopses\" one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpYn3NvCZD2r"
      },
      "outputs": [],
      "source": [
        "# First, create the tf-idf vectors. Look to the other notebook for code\n",
        "# that instantiates sk-learn's tf-idf vectorizer and then creates the vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFU0oDSPZD2r"
      },
      "outputs": [],
      "source": [
        "# Second, create the list of features for future use. As above, look to\n",
        "# the other notebook for an example.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGIf3_uvZD2r"
      },
      "source": [
        "**Data check**. Use the code below to print out the terms associated with the first document, the obituary of Harry Houdini. Note that you may need to modify the variable names if you used different ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hfV-eYsMZD2r"
      },
      "outputs": [],
      "source": [
        "# get the first vector out (for the first synopsis) just to see what it looks like\n",
        "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0]\n",
        "\n",
        "# place tf-idf values in a pandas data frame\n",
        "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=terms, columns=[\"tfidf\"])\n",
        "\n",
        "df.sort_values(by=[\"tfidf\"],ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Determine the optimal number of clusters"
      ],
      "metadata": {
        "id": "ZqUFMGcxutWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n"
      ],
      "metadata": {
        "id": "oBwvyMtMuzE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C-yVbWn1uy9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9s2ohou3uy6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9EjQdJ8ZD2r"
      },
      "source": [
        "### 5. Do the clustering w/ the optimal number of clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdQOraegZD2r"
      },
      "outputs": [],
      "source": [
        "# Look to the other notebook for code that instantiates sk-learn's\n",
        "# k-means clustering model and then fits it to the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-N3c4gUZD2s"
      },
      "source": [
        "**Data check:** Use the code below to dump the cluster assignments into a dataframe for future use. Note that you may need to modify the variable names if you used different ones.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4af_UJvQZD2s"
      },
      "outputs": [],
      "source": [
        "# dump our clusters into a dataframe\n",
        "nyt_obits = { 'title': obit_titles, 'idx': range(tfidf_vectorizer_vectors.shape[0]), 'cluster': clusters }\n",
        "\n",
        "obit_clusters_df = pd.DataFrame(nyt_obits, columns = ['title', 'idx', 'cluster' ])\n",
        "\n",
        "obit_clusters_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66s15dEBZD2s"
      },
      "source": [
        "### 6. Visualize the results\n",
        "\n",
        "Look to the other notebook for code that you can modify for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x-AGy8UZD2s"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFJlX8TqZD2s"
      },
      "source": [
        "Then, see which obituaries were associated with each cluster. Look to the other notebook for code you can modify for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1W6FISXZD2s"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKZfMQ59ZD2s"
      },
      "source": [
        "**Do any of these clusters make intuitive sense?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etum8mdgxZP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJKNDuyBxZNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}